# üçÑ Mushroom Detection

&nbsp;

## üìÑ Descri√ß√£o do Projeto
Este projeto realiza a classifica√ß√£o de cogumelos como comest√≠veis ou venenosos com base em diversas caracter√≠sticas f√≠sicas e ambientais. Usando um conjunto de dados detalhado das esp√©cies **Agaricus** e **Lepiota**, aplicamos t√©cnicas de An√°lise Explorat√≥ria de Dados (EDA), pr√©-processamento e modelagem de Machine Learning para treinar modelos capazes de prever a classe dos cogumelos.

---
  
## üìÇ Estrutura do Projeto
A estrutura do projeto est√° organizada em pastas para facilitar a navega√ß√£o e entendimento:

```bash
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dados_processados.pkl       # Dados j√° processados e prontos para modelagem
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_info.md             # Informa√ß√µes detalhadas sobre o conjunto de dados
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modelo_svm.pkl              # Modelo SVM j√° treinado
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ EDA.ipynb                       # An√°lise Explorat√≥ria de Dados e tratamento inicial
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.ipynb        # Pr√©-processamento e modelagem dos dados
‚îú‚îÄ‚îÄ tests/                              # Testes unit√°rios
‚îÇ   ‚îî‚îÄ‚îÄ test_model_SVM.py               # Arquivo de testes unit√°rios para valida√ß√£o do c√≥digo
‚îú‚îÄ‚îÄ LICENSE                             # Licen√ßa do projeto
‚îú‚îÄ‚îÄ README.md                           # Este arquivo
‚îî‚îÄ‚îÄ requirements.txt                    # Lista de depend√™ncias para o projeto de Detec√ß√£o de Cogumelos
```

---

## üìä An√°lise Explorat√≥ria de Dados (EDA)
O notebook `EDA.ipynb` abrange:

- Carregamento e compreens√£o dos dados.
- Visualiza√ß√£o de distribui√ß√µes e correla√ß√µes entre vari√°veis.
- Tratamento de dados ausentes e categ√≥ricos.
- Gera√ß√£o de insights iniciais sobre os atributos mais relevantes.

---

## üõ†Ô∏è Pr√©-processamento e Modelagem

O notebook `data_preprocessing.ipynb` executa as seguintes etapas essenciais:

1. **Carregamento dos Dados Processados**: Os dados limpos s√£o carregados do arquivo `dados_processados.pkl` para otimizar o tempo de execu√ß√£o.

2. **Sele√ß√£o de Features**: S√£o escolhidas as vari√°veis mais relevantes para melhorar a performance dos modelos.

3. **Divis√£o Treino/Teste**: Os dados s√£o divididos em conjuntos de treino e teste usando `train_test_split`, garantindo boa representatividade e evitando overfitting.

4. **Avalia√ß√£o de Modelos**: S√£o treinados e avaliados diversos modelos de Machine Learning, como KNN, Decision Tree, Random Forest, Logistic Regression, SVM e Redes Neurais, com o SVM apresentando o melhor desempenho.

5. **Ajuste de Hiperpar√¢metros**: O `GridSearchCV` √© usado para otimizar hiperpar√¢metros e aumentar a precis√£o dos modelos.

6. **Valida√ß√£o Cruzada**: A valida√ß√£o cruzada √© aplicada para assegurar a robustez dos modelos e a sua capacidade de generaliza√ß√£o.

---

## üìÅ Estrutura dos Dados

- **Processed**: Cont√©m o arquivo `dados_processados.pkl`, que √© o conjunto de dados ap√≥s o pr√©-processamento. Isso inclui tratamento de valores ausentes, codifica√ß√£o de vari√°veis categ√≥ricas e normaliza√ß√£o, deixando os dados prontos para a modelagem.
- **Raw**: Cont√©m o arquivo `dataset_info.md`, que fornece informa√ß√µes detalhadas sobre o conjunto de dados original, incluindo descri√ß√µes dos atributos, a fonte dos dados e as refer√™ncias para cita√ß√£o. Este arquivo √© √∫til para compreender a estrutura dos dados antes do pr√©-processamento.
- **Model**: Cont√©m o modelo SVM treinado e otimizado, inclu√≠do no arquivo `modelo_svm.pkl`,  para uso futuro. O modelo podem ser facilmente carregado para fazer previs√µes sem a necessidade de re-treinar o algoritmo.

---

## üìà Resultados Comparativos dos Modelos

Os modelos de Machine Learning foram avaliados utilizando **acur√°cia**, **vari√¢ncia** e o **teste de normalidade de Shapiro-Wilk** para medir a performance, estabilidade e adequa√ß√£o dos res√≠duos √† normalidade. Abaixo, est√£o os principais resultados:

| Modelo                           | Acur√°cia | Vari√¢ncia         | Shapiro-Wilk (p-value)  | Coment√°rios                                                                 |
|-----------------------------------|----------|-------------------|-------------------------|-----------------------------------------------------------------------------|
| **Support Vector Machine (SVM)**  | 0.992    | 1.275214e-06      | 0.3161                 | Excelente equil√≠brio entre acur√°cia, baixa vari√¢ncia e res√≠duos relativamente pr√≥ximos √† normalidade. Ideal para dados n√£o lineares e com margens de decis√£o bem definidas. |
| **Logistic Regression**           | 0.876    | 4.583502e-12      | 0.6069                  | Acur√°cia mais baixa comparada a outros modelos, por√©m com excelente estabilidade (baixa vari√¢ncia) e res√≠duos bastante pr√≥ximos da normalidade. Indicado para dados lineares.        |
| **Decision Tree**                 | 1.0      | 0.000000e+00     | 1.0             | Acur√°cia perfeita e vari√¢ncia nula, mas res√≠duos extremamente longe da normalidade. Tend√™ncia ao overfitting, o que pode prejudicar a generaliza√ß√£o do modelo.                                              |
| **Random Forest**                 | 1.0      | 3.904961e-09    | 4.4017            | Acur√°cia perfeita e boa robustez. No entanto, res√≠duos significativamente longe da normalidade, sugerindo problemas com a modelagem dos dados ou alta complexidade.                                       |
| **Neural Networks**               | 1.0      | 1.081776e-07      | 0.0014               | Acur√°cia muito alta, mas com maior vari√¢ncia e res√≠duos longe da normalidade, indicando poss√≠veis ajustes a serem feitos, como tuning de hiperpar√¢metros ou regulariza√ß√£o.                                         |
| **K-Nearest Neighbors (KNN)**     | 1.0   | 1.644531e-08    | 3.8155               | Acur√°cia pr√≥xima de 1.0, mas maior varia√ß√£o nos resultados. Res√≠duos longe da normalidade indicam que o modelo pode n√£o estar capturando bem os padr√µes subjacentes.                       |

---

## üñ•Ô∏è Execu√ß√£o
Para executar este projeto localmente, siga os passos abaixo:

1. Clone o reposit√≥rio:
```bash
   git clone https://github.com/jonathan953/mushroom-detection.git
```

2. Navegue at√© o diret√≥rio do projeto
```bash
  cd mushroom-detection
```

3. Instale as depend√™ncias necess√°rias
```bash
pip install -r requirements.txt
```
4. Execute os notebooks na sequ√™ncia EDA.ipynb e data_preprocessing.ipynb para replicar a an√°lise e os resultados.

 ---

## üèÜ O SVM foi o Melhor Modelo para Classifica√ß√£o de Cogumelos

### 1. Separa√ß√£o de Margem M√°xima
O **Support Vector Machine (SVM)** destacou-se por sua habilidade de encontrar a **margem de separa√ß√£o m√°xima** entre as classes. Isso √© crucial em dados onde as vari√°veis t√™m sobreposi√ß√£o, como no conjunto de cogumelos. Utilizando o **kernel radial (RBF)**, o SVM conseguiu mapear os dados em um espa√ßo de maior dimens√£o, facilitando a separa√ß√£o entre cogumelos comest√≠veis e venenosos, mesmo que os dados n√£o fossem linearmente separ√°veis.

### 2. Controle de Vari√¢ncia e Estabilidade
A vari√¢ncia do **SVM** foi de **1.275214e-06**, um valor que indica um controle moderado da varia√ß√£o, capturando padr√µes complexos sem superajustar aos dados de treino.

#### Compara√ß√£o com outros modelos:
- **Decision Tree** teve uma vari√¢ncia menor (**0.000000e+00**), sugerindo maior estabilidade, mas foi menos eficaz em capturar a complexidade dos dados, indicando overfitting.
- **Random Forest** tamb√©m apresentou vari√¢ncia baixa (**3.904961e-09**), mas, como a Decision Tree, n√£o superou o SVM em termos de precis√£o.
- **K-Nearest Neighbors (KNN)** e **Neural Networks** apresentaram vari√¢ncias maiores do que o SVM, mostrando maior instabilidade nos resultados.

O coeficiente de varia√ß√£o do **SVM** foi **0.0383%**, demonstrando um controle razo√°vel de varia√ß√£o no desempenho. Ele foi mais elevado que os da **Decision Tree** (0.0045%) e da **Random Forest** (0.0049%), mas ainda eficiente, sendo superior em precis√£o.

### 3. Teste de Normalidade dos Res√≠duos (Shapiro-Wilk)
O p-value do **SVM** no teste de **Shapiro-Wilk** foi **0.2865**, sugerindo que os res√≠duos do modelo se aproximam de uma distribui√ß√£o normal. Isso √© um bom indicador da robustez e adequa√ß√£o do modelo aos dados.

#### Compara√ß√£o com outros modelos:
- **√Årvore de Decis√£o** e **Random Forest** apresentaram p-values muito baixos (**4.2396e-11** e **4.2432e-11**, respectivamente), indicando que seus res√≠duos est√£o muito distantes da normalidade, possivelmente devido ao overfitting.
- **Neural Networks** apresentou um p-value muito baixo (**0.0001**), o que, embora mostre boa acur√°cia, sugere problemas significativos de normalidade dos res√≠duos.
- **K-Nearest Neighbors (KNN)** tamb√©m teve res√≠duos distantes da normalidade (p-value de **1.3457e-08**), o que indica que o modelo pode n√£o estar capturando bem os padr√µes subjacentes.
- **Regress√£o Log√≠stica** teve um p-value de **0.1699**, indicando que os res√≠duos est√£o razoavelmente pr√≥ximos da normalidade.


### 4. Flexibilidade com Hiperpar√¢metros
O **SVM** se beneficiou da flexibilidade no ajuste de hiperpar√¢metros como **C** (regulariza√ß√£o) e o tipo de **kernel**. Esses ajustes permitiram ao modelo equilibrar precis√£o e generaliza√ß√£o, sendo uma excelente escolha para dados com padr√µes n√£o lineares, como no caso dos cogumelos.

### 5. Compara√ß√£o com Outros Modelos
- **Decision Tree** e **Random Forest** apresentaram baixa vari√¢ncia e foram est√°veis, mas n√£o conseguiram capturar a complexidade dos dados t√£o bem quanto o **SVM**.
- **Neural Networks**, embora eficaz para lidar com a complexidade, teve res√≠duos significativamente afastados da normalidade, o que pode prejudicar sua consist√™ncia em dados desconhecidos.
- **K-Nearest Neighbors (KNN)** teve uma acur√°cia alta, mas sua maior varia√ß√£o nos resultados e res√≠duos fora da normalidade sugerem uma menor capacidade de generaliza√ß√£o.

---

## ü•à Melhor Alternativa: Logistic Regression

### 1. Baixa Vari√¢ncia e Alta Estabilidade
A **Logistic Regression** destacou-se pela menor vari√¢ncia entre todos os modelos, com um valor de **4.583502e-12**. Isso indica que o modelo √© extremamente est√°vel em suas previs√µes, sendo uma excelente escolha para cen√°rios onde simplicidade e estabilidade s√£o mais importantes que a capacidade de capturar padr√µes complexos ou n√£o lineares.

### 2. Normalidade dos Res√≠duos
No teste de **Shapiro-Wilk**, a **Logistic Regression** apresentou um p-value de **0.1699**, indicando que seus res√≠duos est√£o pr√≥ximos da normalidade. Isso demonstra que, apesar de sua simplicidade, o modelo √© robusto e bem ajustado aos dados.

### 3. Limita√ß√£o em Dados N√£o Lineares
O desempenho inferior da **Logistic Regression** em rela√ß√£o ao **SVM** pode ser explicado por sua limita√ß√£o ao lidar com dados n√£o lineares. Como o conjunto de dados de cogumelos cont√©m vari√°veis com intera√ß√µes mais complexas, o **SVM** (com seu kernel RBF) consegue capturar essas rela√ß√µes n√£o lineares com maior efic√°cia.


---

## Conclus√£o
O **SVM** foi o melhor modelo para a classifica√ß√£o de cogumelos, devido √† sua alta acur√°cia, controle moderado de vari√¢ncia, normalidade dos res√≠duos e flexibilidade em ajustar hiperpar√¢metros. A **Logistic Regression**, embora menos precisa, √© uma excelente alternativa pela sua estabilidade e simplicidade, sendo √∫til em casos onde n√£o h√° tanta necessidade de capturar a complexidade n√£o linear dos dados.

---

## üìù Licen√ßa
Este projeto est√° licenciado sob os termos do Reposit√≥rio de Aprendizado de M√°quina da UCI. Consulte o arquivo `dataset_info.md` para mais detalhes.

Este projeto √© distribu√≠do sob a licen√ßa [MIT](LICENSE).


## ü§ù Contribui√ß√£o
Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir uma issue ou enviar um pull request.


## ‚ú® Agradecimentos
- UCI Machine Learning Repository pela disponibiliza√ß√£o do dataset.