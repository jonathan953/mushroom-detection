# ğŸ„ Mushroom Detection

## ğŸ“„ DescriÃ§Ã£o do Projeto
Este projeto realiza a classificaÃ§Ã£o de cogumelos como comestÃ­veis ou venenosos com base em diversas caracterÃ­sticas fÃ­sicas e ambientais. Usando um conjunto de dados detalhado das espÃ©cies **Agaricus** e **Lepiota**, aplicamos tÃ©cnicas de AnÃ¡lise ExploratÃ³ria de Dados (EDA), prÃ©-processamento e modelagem de Machine Learning para treinar modelos capazes de prever a classe dos cogumelos.


## ğŸ“‚ Estrutura do Projeto
A estrutura do projeto estÃ¡ organizada em pastas para facilitar a navegaÃ§Ã£o e entendimento:

```bash
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â””â”€â”€ dados_processados.pkl       # Dados jÃ¡ processados e prontos para modelagem
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ dataset_info.md             # InformaÃ§Ãµes detalhadas sobre o conjunto de dados
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ modelos.pkl                 # Modelos jÃ¡ treinados
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ EDA.ipynb                       # AnÃ¡lise ExploratÃ³ria de Dados e tratamento inicial
â”‚   â”œâ”€â”€ data_preprocessing.ipynb        # PrÃ©-processamento e modelagem dos dados
â”œâ”€â”€ tests/                              # Testes unitÃ¡rios
â”‚   â””â”€â”€ test_model_SVM.py               # Arquivo de testes unitÃ¡rios para validaÃ§Ã£o do cÃ³digo
â”œâ”€â”€ LICENSE                             # LicenÃ§a do projeto
â”œâ”€â”€ README.md                           # Este arquivo
â””â”€â”€ requirements.txt                    # Lista de dependÃªncias para o projeto de DetecÃ§Ã£o de Cogumelos
```


## ğŸ“Š AnÃ¡lise ExploratÃ³ria de Dados (EDA)
O notebook `EDA.ipynb` abrange:

- Carregamento e compreensÃ£o dos dados.
- VisualizaÃ§Ã£o de distribuiÃ§Ãµes e correlaÃ§Ãµes entre variÃ¡veis.
- Tratamento de dados ausentes e categÃ³ricos.
- GeraÃ§Ã£o de insights iniciais sobre os atributos mais relevantes.


## ğŸ› ï¸ PrÃ©-processamento e Modelagem
O notebook `data_preprocessing.ipynb` aborda:

- Carregamento dos dados processados.
- SeleÃ§Ã£o das principais features para o modelo.
- DivisÃ£o do conjunto de dados em treino e teste.
- ImplementaÃ§Ã£o e avaliaÃ§Ã£o de modelos de Machine Learning, como KNN, Decision Tree, Random Forest, Logistic Regression, SVM e Redes Neurais.
- Ajuste de hiperparÃ¢metros utilizando `GridSearchCV`.
- ValidaÃ§Ã£o cruzada para assegurar a robustez dos modelos.


## ğŸ“ Dados
- **Processed**: ContÃ©m o arquivo `dados_processados.pkl`, que Ã© o conjunto de dados apÃ³s o tratamento e pronto para ser usado na modelagem.
- **Raw**: ContÃ©m o arquivo `dataset_info.md` com as informaÃ§Ãµes detalhadas sobre o conjunto de dados, incluindo a descriÃ§Ã£o dos atributos, fonte e citaÃ§Ã£o.


## ğŸ“ˆ Resultados
Os modelos foram avaliados utilizando mÃ©tricas como acurÃ¡cia, e foi realizada uma busca de hiperparÃ¢metros para otimizar o desempenho dos modelos. A seguir estÃ£o alguns dos resultados alcanÃ§ados:

- **Melhor acurÃ¡cia com Ãrvore de DecisÃ£o**: 1.0
- **Melhor acurÃ¡cia com Random Forest**: 1.0
- **Melhor acurÃ¡cia com KNN**: 0.999
- **Melhor acurÃ¡cia com RegressÃ£o LogÃ­stica**: 0.876
- **Melhor acurÃ¡cia com SVM**: 0.995
- **Melhor acurÃ¡cia com Redes Neurais**: 1.0


## ğŸ–¥ï¸ ExecuÃ§Ã£o
Para executar este projeto localmente, siga os passos abaixo:

1. Clone o repositÃ³rio:
```bash
   git clone https://github.com/jonathan953/mushroom-detection.git
```

2. Navegue atÃ© o diretÃ³rio do projeto
```bash
  cd mushroom-detection
```

3. Instale as dependÃªncias necessÃ¡rias
```bash
pip install -r requirements.txt
```
4. Execute os notebooks na sequÃªncia EDA.ipynb e data_preprocessing.ipynb para replicar a anÃ¡lise e os resultados.

# ğŸ† O SVM foi o Melhor Modelo para ClassificaÃ§Ã£o de Cogumelos

## 1. SeparaÃ§Ã£o de Margem MÃ¡xima
O **SVM** se destacou por sua capacidade de encontrar a **margem de separaÃ§Ã£o mÃ¡xima** entre as classes, o que Ã© essencial em dados onde as variÃ¡veis tÃªm sobreposiÃ§Ã£o, como no conjunto de cogumelos.
Com o uso do **kernel radial (RBF)**, o SVM conseguiu mapear os dados em um espaÃ§o de maior dimensÃ£o, tornando a separaÃ§Ã£o entre cogumelos comestÃ­veis e venenosos mais clara, mesmo que os dados nÃ£o fossem linearmente separÃ¡veis.

## 2. Controle de VariÃ¢ncia e Estabilidade
A variÃ¢ncia do **SVM** foi de **1.458388e-07**, uma variÃ¢ncia moderada, que indica que o modelo conseguiu capturar padrÃµes complexos sem superajustar aos dados de treino.

### Comparado com outros modelos:
- **Ãrvore de DecisÃ£o** teve uma variÃ¢ncia muito menor (**2.022212e-09**), sugerindo maior estabilidade, mas foi menos eficaz em capturar a complexidade dos dados.
- **Random Forest** tambÃ©m apresentou variÃ¢ncia baixa (**2.453148e-09**), mas assim como a Ãrvore de DecisÃ£o, foi superado em termos de precisÃ£o.
- **KNN** e **Rede Neural** apresentaram variÃ¢ncias maiores do que o SVM, indicando maior instabilidade nos resultados.

O coeficiente de variaÃ§Ã£o do **SVM** foi **0.0383%**, mostrando um controle razoÃ¡vel de variaÃ§Ã£o em relaÃ§Ã£o ao desempenho, sendo maior que o de modelos como a **Ãrvore de DecisÃ£o** (0.0045%) e **Random Forest** (0.0049%), mas ainda assim eficiente.

## 3. Teste de Normalidade dos ResÃ­duos (Shapiro-Wilk)
O p-value do **SVM** no teste de **Shapiro-Wilk** foi **0.411**, o que indica que os resÃ­duos do modelo se aproximam de uma distribuiÃ§Ã£o normal, o que Ã© um sinal positivo para a robustez e adequaÃ§Ã£o do modelo aos dados.

### Comparado com outros modelos:
- **Ãrvore de DecisÃ£o** e **Random Forest** apresentaram p-values extremamente baixos (**7.766e-12** e **4.247e-11**, respectivamente), sugerindo que os resÃ­duos se afastam significativamente da normalidade, o que pode impactar a generalizaÃ§Ã£o dos modelos.
- **Rede Neural** tambÃ©m apresentou um p-value muito baixo (**4.164e-09**), o que, embora tenha dado bons resultados, indica resÃ­duos nÃ£o normais.
- **KNN** tambÃ©m nÃ£o teve resÃ­duos prÃ³ximos Ã  normalidade (p-value de **3.195e-08**).

## 4. Flexibilidade com HiperparÃ¢metros
O **SVM** se beneficiou da flexibilidade no ajuste de seus hiperparÃ¢metros, como o valor de **C** (regularizaÃ§Ã£o) e o tipo de **kernel** utilizado. Esses ajustes permitiram ao modelo equilibrar precisÃ£o e generalizaÃ§Ã£o, o que foi essencial para seu desempenho superior.

## 5. ComparaÃ§Ã£o com Outros Modelos
- **Ãrvore de DecisÃ£o** e **Random Forest** apresentaram baixa variÃ¢ncia e foram muito estÃ¡veis, mas nÃ£o conseguiram capturar a complexidade dos dados tÃ£o bem quanto o **SVM**.
- A **Rede Neural**, embora tambÃ©m tenha sido eficaz em lidar com a complexidade, teve resÃ­duos significativamente afastados da normalidade, o que indica que seu desempenho pode ser menos consistente em dados nÃ£o vistos.

---

# ğŸ¥ˆ Melhor Alternativa: RegressÃ£o LogÃ­stica

## 1. Baixa VariÃ¢ncia e Alta Estabilidade
A **RegressÃ£o LogÃ­stica** apresentou a menor variÃ¢ncia entre todos os modelos, com um valor de **3.325033e-12** e o menor coeficiente de variaÃ§Ã£o de **0.000208%**.
Isso indica que a **RegressÃ£o LogÃ­stica** Ã© extremamente estÃ¡vel em suas previsÃµes, sendo uma excelente alternativa para situaÃ§Ãµes onde a simplicidade e a estabilidade sÃ£o mais importantes do que a capacidade de capturar padrÃµes nÃ£o lineares.

## 2. Normalidade dos ResÃ­duos
No teste de **Shapiro-Wilk**, a **RegressÃ£o LogÃ­stica** apresentou um p-value de **0.2440**, indicando que seus resÃ­duos tambÃ©m se aproximam da normalidade, embora nÃ£o tanto quanto o **SVM**.
Isso mostra que, apesar de sua simplicidade, a **RegressÃ£o LogÃ­stica** ainda se comporta de maneira robusta em relaÃ§Ã£o Ã  adequaÃ§Ã£o aos dados.

## 3. LimitaÃ§Ã£o em Dados NÃ£o Lineares
O desempenho inferior da **RegressÃ£o LogÃ­stica** em comparaÃ§Ã£o ao **SVM** pode ser explicado por sua incapacidade de lidar com dados nÃ£o lineares. O conjunto de dados de cogumelos contÃ©m variÃ¡veis com relaÃ§Ãµes complexas, o que favorece o uso de modelos como o **SVM** que podem lidar com essa nÃ£o linearidade.


## ğŸ“ LicenÃ§a
Este projeto estÃ¡ licenciado sob os termos do RepositÃ³rio de Aprendizado de MÃ¡quina da UCI. Consulte o arquivo `dataset_info.md` para mais detalhes.

Este projeto Ã© distribuÃ­do sob a licenÃ§a [MIT](LICENSE).

## ğŸ¤ ContribuiÃ§Ã£o
ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir uma issue ou enviar um pull request.


## âœ¨ Agradecimentos
- UCI Machine Learning Repository pela disponibilizaÃ§Ã£o do dataset.