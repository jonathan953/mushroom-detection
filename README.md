# üçÑ Mushroom Detection

## üìÑ Descri√ß√£o do Projeto
Este projeto realiza a classifica√ß√£o de cogumelos como comest√≠veis ou venenosos com base em diversas caracter√≠sticas f√≠sicas e ambientais. Usando um conjunto de dados detalhado das esp√©cies **Agaricus** e **Lepiota**, aplicamos t√©cnicas de An√°lise Explorat√≥ria de Dados (EDA), pr√©-processamento e modelagem de Machine Learning para treinar modelos capazes de prever a classe dos cogumelos.


## üìÇ Estrutura do Projeto
A estrutura do projeto est√° organizada em pastas para facilitar a navega√ß√£o e entendimento:

```bash
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dados_processados.pkl       # Dados j√° processados e prontos para modelagem
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_info.md             # Informa√ß√µes detalhadas sobre o conjunto de dados
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modelos.pkl                 # Modelos j√° treinados
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ EDA.ipynb                       # An√°lise Explorat√≥ria de Dados e tratamento inicial
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.ipynb        # Pr√©-processamento e modelagem dos dados
‚îú‚îÄ‚îÄ tests/                              # Testes unit√°rios
‚îÇ   ‚îî‚îÄ‚îÄ test_model_SVM.py               # Arquivo de testes unit√°rios para valida√ß√£o do c√≥digo
‚îú‚îÄ‚îÄ LICENSE                             # Licen√ßa do projeto
‚îú‚îÄ‚îÄ README.md                           # Este arquivo
‚îî‚îÄ‚îÄ requirements.txt                    # Lista de depend√™ncias para o projeto de Detec√ß√£o de Cogumelos
```


## üìä An√°lise Explorat√≥ria de Dados (EDA)
O notebook `EDA.ipynb` abrange:

- Carregamento e compreens√£o dos dados.
- Visualiza√ß√£o de distribui√ß√µes e correla√ß√µes entre vari√°veis.
- Tratamento de dados ausentes e categ√≥ricos.
- Gera√ß√£o de insights iniciais sobre os atributos mais relevantes.


## üõ†Ô∏è Pr√©-processamento e Modelagem

O notebook `data_preprocessing.ipynb` executa as seguintes etapas essenciais:

1. **Carregamento dos Dados Processados**: Os dados limpos s√£o carregados do arquivo `dados_processados.pkl` para otimizar o tempo de execu√ß√£o.

2. **Sele√ß√£o de Features**: S√£o escolhidas as vari√°veis mais relevantes para melhorar a performance dos modelos.

3. **Divis√£o Treino/Teste**: Os dados s√£o divididos em conjuntos de treino e teste usando `train_test_split`, garantindo boa representatividade e evitando overfitting.

4. **Avalia√ß√£o de Modelos**: S√£o treinados e avaliados diversos modelos de Machine Learning, como KNN, Decision Tree, Random Forest, Logistic Regression, SVM e Redes Neurais, com o SVM apresentando o melhor desempenho.

5. **Ajuste de Hiperpar√¢metros**: O `GridSearchCV` √© usado para otimizar hiperpar√¢metros e aumentar a precis√£o dos modelos.

6. **Valida√ß√£o Cruzada**: A valida√ß√£o cruzada √© aplicada para assegurar a robustez dos modelos e a sua capacidade de generaliza√ß√£o.



## üìÅ Estrutura dos Dados

- **Processed**: Cont√©m o arquivo `dados_processados.pkl`, que √© o conjunto de dados ap√≥s o pr√©-processamento. Isso inclui tratamento de valores ausentes, codifica√ß√£o de vari√°veis categ√≥ricas e normaliza√ß√£o, deixando os dados prontos para a modelagem.
- **Raw**: Cont√©m o arquivo `dataset_info.md`, que fornece informa√ß√µes detalhadas sobre o conjunto de dados original, incluindo descri√ß√µes dos atributos, a fonte dos dados e as refer√™ncias para cita√ß√£o. Este arquivo √© √∫til para compreender a estrutura dos dados antes do pr√©-processamento.
- **Model**: Cont√©m os modelos treinados e otimizados, incluindo o arquivo `modelos.pkl`, onde os melhores modelos ajustados, como o **SVM**, s√£o salvos para uso futuro. Esses modelos podem ser facilmente carregados para fazer previs√µes sem a necessidade de re-treinar os algoritmos.



## üìà Resultados Comparativos dos Modelos

Os modelos de Machine Learning foram avaliados utilizando **acur√°cia**, **vari√¢ncia** e o **teste de normalidade de Shapiro-Wilk** para medir a performance, estabilidade e adequa√ß√£o dos res√≠duos √† normalidade. Abaixo, est√£o os principais resultados:

| Modelo                           | Acur√°cia | Vari√¢ncia         | Shapiro-Wilk (p-value)  | Coment√°rios                                                                 |
|-----------------------------------|----------|-------------------|-------------------------|-----------------------------------------------------------------------------|
| **Support Vector Machine (SVM)**  | 0.995    | 1.458388e-07      | 0.4114                  | Excelente equil√≠brio entre acur√°cia, vari√¢ncia e res√≠duos mais pr√≥ximos da normalidade. Ideal para dados n√£o lineares. |
| **Logistic Regression**           | 0.876    | 3.325033e-12      | 0.2440                  | Maior estabilidade com a menor vari√¢ncia, res√≠duos pr√≥ximos da normalidade, mas limitada em dados n√£o lineares.        |
| **Decision Tree**                 | 1.0      | 2.022212e-09      | 7.766e-12               | Alta acur√°cia, excelente estabilidade, mas res√≠duos longe da normalidade.                                              |
| **Random Forest**                 | 1.0      | 2.453148e-09      | 4.247e-11               | Alta estabilidade e robustez, mas com res√≠duos tamb√©m distantes da normalidade.                                       |
| **Neural Networks**               | 1.0      | 1.955648e-08      | 4.164e-09               | Acur√°cia perfeita, por√©m com maior vari√¢ncia e res√≠duos longe da normalidade.                                         |
| **K-Nearest Neighbors (KNN)**     | 0.999    | 4.293965e-08      | 3.195e-08               | Acur√°cia pr√≥xima de 1.0, mas com maior varia√ß√£o nos resultados e res√≠duos longe da normalidade.                       |



## üñ•Ô∏è Execu√ß√£o
Para executar este projeto localmente, siga os passos abaixo:

1. Clone o reposit√≥rio:
```bash
   git clone https://github.com/jonathan953/mushroom-detection.git
```

2. Navegue at√© o diret√≥rio do projeto
```bash
  cd mushroom-detection
```

3. Instale as depend√™ncias necess√°rias
```bash
pip install -r requirements.txt
```
4. Execute os notebooks na sequ√™ncia EDA.ipynb e data_preprocessing.ipynb para replicar a an√°lise e os resultados.

 

## üèÜ O SVM foi o Melhor Modelo para Classifica√ß√£o de Cogumelos

### 1. Separa√ß√£o de Margem M√°xima
O **Support Vector Machine (SVM)** se destacou por sua capacidade de encontrar a **margem de separa√ß√£o m√°xima** entre as classes, o que √© essencial em dados onde as vari√°veis t√™m sobreposi√ß√£o, como no conjunto de cogumelos.
Com o uso do **kernel radial (RBF)**, o SVM conseguiu mapear os dados em um espa√ßo de maior dimens√£o, tornando a separa√ß√£o entre cogumelos comest√≠veis e venenosos mais clara, mesmo que os dados n√£o fossem linearmente separ√°veis.

### 2. Controle de Vari√¢ncia e Estabilidade
A vari√¢ncia do **SVM** foi de **1.458388e-07**, uma vari√¢ncia moderada, que indica que o modelo conseguiu capturar padr√µes complexos sem superajustar aos dados de treino.

#### Comparado com outros modelos:
- **Decision Tree** teve uma vari√¢ncia muito menor (**2.022212e-09**), sugerindo maior estabilidade, mas foi menos eficaz em capturar a complexidade dos dados.
- **Random Forest** tamb√©m apresentou vari√¢ncia baixa (**2.453148e-09**), mas assim como a Decision Tree, foi superado em termos de precis√£o.
- **K-Nearest Neighbors (KNN)** e **Neural Networks** apresentaram vari√¢ncias maiores do que o SVM, indicando maior instabilidade nos resultados.

O coeficiente de varia√ß√£o do **SVM** foi **0.0383%**, mostrando um controle razo√°vel de varia√ß√£o em rela√ß√£o ao desempenho, sendo maior que o de modelos como a **Decision Tree** (0.0045%) e **Random Forest** (0.0049%), mas ainda assim eficiente.

### 3. Teste de Normalidade dos Res√≠duos (Shapiro-Wilk)
O p-value do **SVM** no teste de **Shapiro-Wilk** foi **0.411**, o que indica que os res√≠duos do modelo se aproximam de uma distribui√ß√£o normal, o que √© um sinal positivo para a robustez e adequa√ß√£o do modelo aos dados.

#### Comparado com outros modelos:
- **Decision Tree** e **Random Forest** apresentaram p-values extremamente baixos (**7.766e-12** e **4.247e-11**, respectivamente), sugerindo que os res√≠duos se afastam significativamente da normalidade, o que pode impactar a generaliza√ß√£o dos modelos.
- **Neural Networks** tamb√©m apresentou um p-value muito baixo (**4.164e-09**), o que, embora tenha dado bons resultados, indica res√≠duos n√£o normais.
- **K-Nearest Neighbors (KNN)** tamb√©m n√£o teve res√≠duos pr√≥ximos √† normalidade (p-value de **3.195e-08**).

### 4. Flexibilidade com Hiperpar√¢metros
O **SVM** se beneficiou da flexibilidade no ajuste de seus hiperpar√¢metros, como o valor de **C** (regulariza√ß√£o) e o tipo de **kernel** utilizado. Esses ajustes permitiram ao modelo equilibrar precis√£o e generaliza√ß√£o, o que foi essencial para seu desempenho superior.

### 5. Compara√ß√£o com Outros Modelos
- **Decision Tree** e **Random Forest** apresentaram baixa vari√¢ncia e foram muito est√°veis, mas n√£o conseguiram capturar a complexidade dos dados t√£o bem quanto o **SVM**.
- **Neural Networks**, embora tamb√©m tenha sido eficaz em lidar com a complexidade, teve res√≠duos significativamente afastados da normalidade, o que indica que seu desempenho pode ser menos consistente em dados n√£o vistos.

---

## ü•à Melhor Alternativa: Logistic Regression

### 1. Baixa Vari√¢ncia e Alta Estabilidade
A **Logistic Regression** apresentou a menor vari√¢ncia entre todos os modelos, com um valor de **3.325033e-12** e o menor coeficiente de varia√ß√£o de **0.000208%**.
Isso indica que a **Logistic Regression** √© extremamente est√°vel em suas previs√µes, sendo uma excelente alternativa para situa√ß√µes onde a simplicidade e a estabilidade s√£o mais importantes do que a capacidade de capturar padr√µes n√£o lineares.

### 2. Normalidade dos Res√≠duos
No teste de **Shapiro-Wilk**, a **Logistic Regression** apresentou um p-value de **0.2440**, indicando que seus res√≠duos tamb√©m se aproximam da normalidade, embora n√£o tanto quanto o **SVM**.
Isso mostra que, apesar de sua simplicidade, a **Logistic Regression** ainda se comporta de maneira robusta em rela√ß√£o √† adequa√ß√£o aos dados.

### 3. Limita√ß√£o em Dados N√£o Lineares
O desempenho inferior da **Logistic Regression** em compara√ß√£o ao **SVM** pode ser explicado por sua incapacidade de lidar com dados n√£o lineares. O conjunto de dados de cogumelos cont√©m vari√°veis com rela√ß√µes complexas, o que favorece o uso de modelos como o **SVM** que podem lidar com essa n√£o linearidade.


## üìù Licen√ßa
Este projeto est√° licenciado sob os termos do Reposit√≥rio de Aprendizado de M√°quina da UCI. Consulte o arquivo `dataset_info.md` para mais detalhes.

Este projeto √© distribu√≠do sob a licen√ßa [MIT](LICENSE).

## ü§ù Contribui√ß√£o
Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir uma issue ou enviar um pull request.


## ‚ú® Agradecimentos
- UCI Machine Learning Repository pela disponibiliza√ß√£o do dataset.